# Hand-Gesture-Based-Sign-Language-Recognition-using-CNN
This project aims to create a web application that can detect sign language using Convolutional Neural Networks (CNN) and Flask framework. The application allows users to upload a video file and detects sign language in real-time.

## Installation<br>
1. **Clone this repository**
https://github.com/sanjai002/Hand-Gesture-Based-Sign-Language-Recognition-using-CNN.git

2. **Install the required dependencies using the command**
    ```bash
      pip install -r requirements.txt

3. **To run the application navigate to the root directory of the project and run the following command in your terminal**
   ```bash
   python app.py
The application will start running on your local server, and you can access it in your web browser at http://localhost:5000/

## Dataset
We used the [ASL Alphabet dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet/download?datasetVersionNumber=1) from Kaggle to train our CNN model. The dataset contains 87,000 images of the American Sign Language alphabet.

## Training the Model
1.Download the [ASL Alphabet dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet/download?datasetVersionNumber=1) from Kaggle. Extract the folder and rename it as dataset.

2.To train the CNN model. Run the train.ipynb file


